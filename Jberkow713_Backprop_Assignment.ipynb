{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jberkow713_Backprop_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jberkow713/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Jberkow713_Backprop_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Backpropagation Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Using TensorFlow Keras, Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 0  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 1 |\n",
        "| 0  | 1  | 0  | 1 |\n",
        "| 1  | 0  | 0  | 1 |\n",
        "| 1  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 0  | 0 |\n",
        "\n",
        "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn.\n",
        "\n",
        "This is your \"Hello World!\" of TensorFlow.\n",
        "\n",
        "### Example TensorFlow Starter Code\n",
        "\n",
        "```python \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(3, activation='sigmoid', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "results = model.fit(X,y, epochs=100)\n",
        "\n",
        "```\n",
        "\n",
        "### Additional Written Tasks:\n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofkrQpYZ67Wc",
        "colab_type": "text"
      },
      "source": [
        "### Build a Tensor Keras Perceptron\n",
        "\n",
        "Try to match the architecture we used on Monday - inputs nodes and one output node. Apply this architecture to the XOR-ish dataset above. \n",
        "\n",
        "After fitting your model answer these questions: \n",
        "\n",
        "Are you able to achieve the same results as a bigger architecture from the first part of the assignment? Why is this disparity the case? What properties of the XOR dataset would cause this disparity? \n",
        "\n",
        "Now extrapolate this behavior on a much larger dataset in terms of features. What kind of architecture decisions could we make to avoid the problems the XOR dataset presents at scale? \n",
        "\n",
        "*Note:* The bias term is baked in by default in the Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vsFDODD67Wh",
        "colab_type": "code",
        "outputId": "4b16076d-a9f3-47ea-83c3-2cde66f4b260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = { 'x1':  [0, 0, 1, 0, 1, 1, 0],\n",
        "          'x2': [0, 1, 0, 1, 0, 1, 0],\n",
        "          'x3':  [1, 1, 1, 0, 0, 1, 0],\n",
        "          'y':  [0, 1, 1, 1, 1, 0, 0],\n",
        "          \n",
        "       }\n",
        "\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  x3  y\n",
              "0   0   0   1  0\n",
              "1   0   1   1  1\n",
              "2   1   0   1  1\n",
              "3   0   1   0  1\n",
              "4   1   0   0  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVyInMPEC3f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[0:4, [0, 1, 2]].values\n",
        "y = df.iloc[0:4, [3]].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6VcWw4yC3iE",
        "colab_type": "code",
        "outputId": "5bf04ddc-dcfe-4520-8dfd-1d6b5b2d6c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8mpW21PC3kX",
        "colab_type": "code",
        "outputId": "a3e10151-b135-48d7-861e-155d0e29220a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GK9Ba-xFwGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "nn.train(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpmUefpKGk2P",
        "colab_type": "code",
        "outputId": "a646ac87-f74a-426d-f013-88b85f0c7884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "nn.o_error"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5],\n",
              "       [ 0.5],\n",
              "       [ 0.5],\n",
              "       [ 0.5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdGjz8cGJOY_",
        "colab_type": "code",
        "outputId": "e8f35603-8b23-4ff3-b7de-c352622404f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# This is our perceptron from Monday's by-hand: \n",
        "model = Sequential()\n",
        "model.add(Dense(1,input_dim=3, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X,y, epochs=423)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8782 - accuracy: 0.2500\n",
            "Epoch 2/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8770 - accuracy: 0.2500\n",
            "Epoch 3/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8759 - accuracy: 0.2500\n",
            "Epoch 4/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8748 - accuracy: 0.2500\n",
            "Epoch 5/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8737 - accuracy: 0.2500\n",
            "Epoch 6/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.2500\n",
            "Epoch 7/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.2500\n",
            "Epoch 8/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8703 - accuracy: 0.2500\n",
            "Epoch 9/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8692 - accuracy: 0.2500\n",
            "Epoch 10/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.2500\n",
            "Epoch 11/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8670 - accuracy: 0.2500\n",
            "Epoch 12/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8659 - accuracy: 0.2500\n",
            "Epoch 13/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8647 - accuracy: 0.2500\n",
            "Epoch 14/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.2500\n",
            "Epoch 15/423\n",
            "1/1 [==============================] - 0s 928us/step - loss: 0.8625 - accuracy: 0.2500\n",
            "Epoch 16/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8614 - accuracy: 0.2500\n",
            "Epoch 17/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.2500\n",
            "Epoch 18/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8592 - accuracy: 0.2500\n",
            "Epoch 19/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8581 - accuracy: 0.2500\n",
            "Epoch 20/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.2500\n",
            "Epoch 21/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8559 - accuracy: 0.2500\n",
            "Epoch 22/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8548 - accuracy: 0.2500\n",
            "Epoch 23/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8537 - accuracy: 0.2500\n",
            "Epoch 24/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8526 - accuracy: 0.2500\n",
            "Epoch 25/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8515 - accuracy: 0.2500\n",
            "Epoch 26/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8505 - accuracy: 0.2500\n",
            "Epoch 27/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8494 - accuracy: 0.2500\n",
            "Epoch 28/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8483 - accuracy: 0.2500\n",
            "Epoch 29/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8472 - accuracy: 0.2500\n",
            "Epoch 30/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8461 - accuracy: 0.2500\n",
            "Epoch 31/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8450 - accuracy: 0.2500\n",
            "Epoch 32/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8440 - accuracy: 0.2500\n",
            "Epoch 33/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8429 - accuracy: 0.2500\n",
            "Epoch 34/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8418 - accuracy: 0.2500\n",
            "Epoch 35/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8408 - accuracy: 0.2500\n",
            "Epoch 36/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8397 - accuracy: 0.2500\n",
            "Epoch 37/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8386 - accuracy: 0.2500\n",
            "Epoch 38/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8376 - accuracy: 0.2500\n",
            "Epoch 39/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8365 - accuracy: 0.2500\n",
            "Epoch 40/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8354 - accuracy: 0.2500\n",
            "Epoch 41/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8344 - accuracy: 0.2500\n",
            "Epoch 42/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8333 - accuracy: 0.2500\n",
            "Epoch 43/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8323 - accuracy: 0.2500\n",
            "Epoch 44/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8312 - accuracy: 0.2500\n",
            "Epoch 45/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8302 - accuracy: 0.2500\n",
            "Epoch 46/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.2500\n",
            "Epoch 47/423\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8281 - accuracy: 0.2500\n",
            "Epoch 48/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8270 - accuracy: 0.2500\n",
            "Epoch 49/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8260 - accuracy: 0.2500\n",
            "Epoch 50/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8250 - accuracy: 0.2500\n",
            "Epoch 51/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8239 - accuracy: 0.5000\n",
            "Epoch 52/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8229 - accuracy: 0.5000\n",
            "Epoch 53/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8218 - accuracy: 0.5000\n",
            "Epoch 54/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8208 - accuracy: 0.5000\n",
            "Epoch 55/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8198 - accuracy: 0.5000\n",
            "Epoch 56/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8188 - accuracy: 0.5000\n",
            "Epoch 57/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8177 - accuracy: 0.5000\n",
            "Epoch 58/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8167 - accuracy: 0.5000\n",
            "Epoch 59/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8157 - accuracy: 0.5000\n",
            "Epoch 60/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8147 - accuracy: 0.5000\n",
            "Epoch 61/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8137 - accuracy: 0.5000\n",
            "Epoch 62/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8126 - accuracy: 0.5000\n",
            "Epoch 63/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8116 - accuracy: 0.5000\n",
            "Epoch 64/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8106 - accuracy: 0.5000\n",
            "Epoch 65/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8096 - accuracy: 0.5000\n",
            "Epoch 66/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8086 - accuracy: 0.5000\n",
            "Epoch 67/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8076 - accuracy: 0.5000\n",
            "Epoch 68/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.5000\n",
            "Epoch 69/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8056 - accuracy: 0.5000\n",
            "Epoch 70/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8046 - accuracy: 0.5000\n",
            "Epoch 71/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8036 - accuracy: 0.5000\n",
            "Epoch 72/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8026 - accuracy: 0.5000\n",
            "Epoch 73/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.5000\n",
            "Epoch 74/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8006 - accuracy: 0.5000\n",
            "Epoch 75/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7996 - accuracy: 0.5000\n",
            "Epoch 76/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7987 - accuracy: 0.5000\n",
            "Epoch 77/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7977 - accuracy: 0.5000\n",
            "Epoch 78/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7967 - accuracy: 0.5000\n",
            "Epoch 79/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.5000\n",
            "Epoch 80/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7947 - accuracy: 0.5000\n",
            "Epoch 81/423\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7938 - accuracy: 0.5000\n",
            "Epoch 82/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7928 - accuracy: 0.5000\n",
            "Epoch 83/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7918 - accuracy: 0.5000\n",
            "Epoch 84/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.5000\n",
            "Epoch 85/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7899 - accuracy: 0.5000\n",
            "Epoch 86/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7889 - accuracy: 0.5000\n",
            "Epoch 87/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7879 - accuracy: 0.5000\n",
            "Epoch 88/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7870 - accuracy: 0.5000\n",
            "Epoch 89/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7860 - accuracy: 0.5000\n",
            "Epoch 90/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7851 - accuracy: 0.5000\n",
            "Epoch 91/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.5000\n",
            "Epoch 92/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7832 - accuracy: 0.5000\n",
            "Epoch 93/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7822 - accuracy: 0.5000\n",
            "Epoch 94/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7813 - accuracy: 0.5000\n",
            "Epoch 95/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.5000\n",
            "Epoch 96/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7794 - accuracy: 0.5000\n",
            "Epoch 97/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7784 - accuracy: 0.5000\n",
            "Epoch 98/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7775 - accuracy: 0.5000\n",
            "Epoch 99/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.5000\n",
            "Epoch 100/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7756 - accuracy: 0.5000\n",
            "Epoch 101/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7747 - accuracy: 0.5000\n",
            "Epoch 102/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7737 - accuracy: 0.5000\n",
            "Epoch 103/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.5000\n",
            "Epoch 104/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7719 - accuracy: 0.5000\n",
            "Epoch 105/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.5000\n",
            "Epoch 106/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7700 - accuracy: 0.5000\n",
            "Epoch 107/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7691 - accuracy: 0.5000\n",
            "Epoch 108/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.5000\n",
            "Epoch 109/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7673 - accuracy: 0.5000\n",
            "Epoch 110/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7663 - accuracy: 0.5000\n",
            "Epoch 111/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7654 - accuracy: 0.5000\n",
            "Epoch 112/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7645 - accuracy: 0.5000\n",
            "Epoch 113/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7636 - accuracy: 0.5000\n",
            "Epoch 114/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7627 - accuracy: 0.5000\n",
            "Epoch 115/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7618 - accuracy: 0.5000\n",
            "Epoch 116/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7609 - accuracy: 0.5000\n",
            "Epoch 117/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7600 - accuracy: 0.5000\n",
            "Epoch 118/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7591 - accuracy: 0.5000\n",
            "Epoch 119/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.5000\n",
            "Epoch 120/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7573 - accuracy: 0.5000\n",
            "Epoch 121/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7564 - accuracy: 0.5000\n",
            "Epoch 122/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7555 - accuracy: 0.5000\n",
            "Epoch 123/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7546 - accuracy: 0.5000\n",
            "Epoch 124/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7537 - accuracy: 0.5000\n",
            "Epoch 125/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7528 - accuracy: 0.5000\n",
            "Epoch 126/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.5000\n",
            "Epoch 127/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7510 - accuracy: 0.5000\n",
            "Epoch 128/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.5000\n",
            "Epoch 129/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7493 - accuracy: 0.5000\n",
            "Epoch 130/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.5000\n",
            "Epoch 131/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.5000\n",
            "Epoch 132/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.5000\n",
            "Epoch 133/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.5000\n",
            "Epoch 134/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7449 - accuracy: 0.5000\n",
            "Epoch 135/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7440 - accuracy: 0.5000\n",
            "Epoch 136/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.5000\n",
            "Epoch 137/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7423 - accuracy: 0.5000\n",
            "Epoch 138/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.5000\n",
            "Epoch 139/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.5000\n",
            "Epoch 140/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.5000\n",
            "Epoch 141/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.5000\n",
            "Epoch 142/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7380 - accuracy: 0.5000\n",
            "Epoch 143/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7372 - accuracy: 0.5000\n",
            "Epoch 144/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7363 - accuracy: 0.5000\n",
            "Epoch 145/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.5000\n",
            "Epoch 146/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7346 - accuracy: 0.5000\n",
            "Epoch 147/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7338 - accuracy: 0.5000\n",
            "Epoch 148/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7329 - accuracy: 0.5000\n",
            "Epoch 149/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7321 - accuracy: 0.5000\n",
            "Epoch 150/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.5000\n",
            "Epoch 151/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.5000\n",
            "Epoch 152/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.5000\n",
            "Epoch 153/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.5000\n",
            "Epoch 154/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7279 - accuracy: 0.5000\n",
            "Epoch 155/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7271 - accuracy: 0.5000\n",
            "Epoch 156/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7262 - accuracy: 0.5000\n",
            "Epoch 157/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.5000\n",
            "Epoch 158/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7246 - accuracy: 0.5000\n",
            "Epoch 159/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.5000\n",
            "Epoch 160/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.5000\n",
            "Epoch 161/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7221 - accuracy: 0.5000\n",
            "Epoch 162/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.5000\n",
            "Epoch 163/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.5000\n",
            "Epoch 164/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7197 - accuracy: 0.5000\n",
            "Epoch 165/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.5000\n",
            "Epoch 166/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.5000\n",
            "Epoch 167/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.5000\n",
            "Epoch 168/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.5000\n",
            "Epoch 169/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.5000\n",
            "Epoch 170/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.5000\n",
            "Epoch 171/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.5000\n",
            "Epoch 172/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.5000\n",
            "Epoch 173/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.5000\n",
            "Epoch 174/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.5000\n",
            "Epoch 175/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.5000\n",
            "Epoch 176/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.5000\n",
            "Epoch 177/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7093 - accuracy: 0.5000\n",
            "Epoch 178/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.5000\n",
            "Epoch 179/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.5000\n",
            "Epoch 180/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.5000\n",
            "Epoch 181/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.5000\n",
            "Epoch 182/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.5000\n",
            "Epoch 183/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.5000\n",
            "Epoch 184/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.5000\n",
            "Epoch 185/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.5000\n",
            "Epoch 186/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.5000\n",
            "Epoch 187/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.5000\n",
            "Epoch 188/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.5000\n",
            "Epoch 189/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.5000\n",
            "Epoch 190/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.5000\n",
            "Epoch 191/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 192/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 193/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 194/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 195/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 196/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 197/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 198/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 199/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 200/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 201/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5000\n",
            "Epoch 202/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.7500\n",
            "Epoch 203/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.7500\n",
            "Epoch 204/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.7500\n",
            "Epoch 205/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.7500\n",
            "Epoch 206/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7500\n",
            "Epoch 207/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.7500\n",
            "Epoch 208/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.7500\n",
            "Epoch 209/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.7500\n",
            "Epoch 210/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.7500\n",
            "Epoch 211/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.7500\n",
            "Epoch 212/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.7500\n",
            "Epoch 213/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.7500\n",
            "Epoch 214/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.7500\n",
            "Epoch 215/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.7500\n",
            "Epoch 216/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.7500\n",
            "Epoch 217/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.7500\n",
            "Epoch 218/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.7500\n",
            "Epoch 219/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.7500\n",
            "Epoch 220/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.7500\n",
            "Epoch 221/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.7500\n",
            "Epoch 222/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.7500\n",
            "Epoch 223/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.7500\n",
            "Epoch 224/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.7500\n",
            "Epoch 225/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.7500\n",
            "Epoch 226/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.7500\n",
            "Epoch 227/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.7500\n",
            "Epoch 228/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7500\n",
            "Epoch 229/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.7500\n",
            "Epoch 230/423\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6700 - accuracy: 0.7500\n",
            "Epoch 231/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7500\n",
            "Epoch 232/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.7500\n",
            "Epoch 233/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.7500\n",
            "Epoch 234/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.7500\n",
            "Epoch 235/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.7500\n",
            "Epoch 236/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.7500\n",
            "Epoch 237/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.7500\n",
            "Epoch 238/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.7500\n",
            "Epoch 239/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.7500\n",
            "Epoch 240/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.7500\n",
            "Epoch 241/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.7500\n",
            "Epoch 242/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.7500\n",
            "Epoch 243/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.7500\n",
            "Epoch 244/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.7500\n",
            "Epoch 245/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.7500\n",
            "Epoch 246/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7500\n",
            "Epoch 247/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.7500\n",
            "Epoch 248/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.7500\n",
            "Epoch 249/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.7500\n",
            "Epoch 250/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.7500\n",
            "Epoch 251/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.7500\n",
            "Epoch 252/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.7500\n",
            "Epoch 253/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.7500\n",
            "Epoch 254/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.7500\n",
            "Epoch 255/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.7500\n",
            "Epoch 256/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7500\n",
            "Epoch 257/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.7500\n",
            "Epoch 258/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7500\n",
            "Epoch 259/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7500\n",
            "Epoch 260/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.7500\n",
            "Epoch 261/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7500\n",
            "Epoch 262/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.7500\n",
            "Epoch 263/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.7500\n",
            "Epoch 264/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.7500\n",
            "Epoch 265/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.7500\n",
            "Epoch 266/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.7500\n",
            "Epoch 267/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.7500\n",
            "Epoch 268/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7500\n",
            "Epoch 269/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.7500\n",
            "Epoch 270/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7500\n",
            "Epoch 271/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.7500\n",
            "Epoch 272/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.7500\n",
            "Epoch 273/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.7500\n",
            "Epoch 274/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.7500\n",
            "Epoch 275/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.7500\n",
            "Epoch 276/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.7500\n",
            "Epoch 277/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.7500\n",
            "Epoch 278/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6384 - accuracy: 0.7500\n",
            "Epoch 279/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7500\n",
            "Epoch 280/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7500\n",
            "Epoch 281/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.7500\n",
            "Epoch 282/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.7500\n",
            "Epoch 283/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.7500\n",
            "Epoch 284/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.7500\n",
            "Epoch 285/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7500\n",
            "Epoch 286/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7500\n",
            "Epoch 287/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.7500\n",
            "Epoch 288/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6323 - accuracy: 0.7500\n",
            "Epoch 289/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.7500\n",
            "Epoch 290/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.7500\n",
            "Epoch 291/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.7500\n",
            "Epoch 292/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7500\n",
            "Epoch 293/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7500\n",
            "Epoch 294/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.7500\n",
            "Epoch 295/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.7500\n",
            "Epoch 296/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.7500\n",
            "Epoch 297/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.7500\n",
            "Epoch 298/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.7500\n",
            "Epoch 299/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.7500\n",
            "Epoch 300/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.7500\n",
            "Epoch 301/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.7500\n",
            "Epoch 302/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.7500\n",
            "Epoch 303/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.7500\n",
            "Epoch 304/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.7500\n",
            "Epoch 305/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.7500\n",
            "Epoch 306/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.7500\n",
            "Epoch 307/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.7500\n",
            "Epoch 308/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.7500\n",
            "Epoch 309/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.7500\n",
            "Epoch 310/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.7500\n",
            "Epoch 311/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.7500\n",
            "Epoch 312/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.7500\n",
            "Epoch 313/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.7500\n",
            "Epoch 314/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.7500\n",
            "Epoch 315/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7500\n",
            "Epoch 316/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.7500\n",
            "Epoch 317/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.7500\n",
            "Epoch 318/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7500\n",
            "Epoch 319/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.7500\n",
            "Epoch 320/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.7500\n",
            "Epoch 321/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.7500\n",
            "Epoch 322/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7500\n",
            "Epoch 323/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7500\n",
            "Epoch 324/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7500\n",
            "Epoch 325/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.7500\n",
            "Epoch 326/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7500\n",
            "Epoch 327/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.7500\n",
            "Epoch 328/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7500\n",
            "Epoch 329/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.7500\n",
            "Epoch 330/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.7500\n",
            "Epoch 331/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7500\n",
            "Epoch 332/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7500\n",
            "Epoch 333/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.7500\n",
            "Epoch 334/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7500\n",
            "Epoch 335/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7500\n",
            "Epoch 336/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7500\n",
            "Epoch 337/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.7500\n",
            "Epoch 338/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7500\n",
            "Epoch 339/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.7500\n",
            "Epoch 340/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.7500\n",
            "Epoch 341/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.7500\n",
            "Epoch 342/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7500\n",
            "Epoch 343/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7500\n",
            "Epoch 344/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7500\n",
            "Epoch 345/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7500\n",
            "Epoch 346/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7500\n",
            "Epoch 347/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7500\n",
            "Epoch 348/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7500\n",
            "Epoch 349/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7500\n",
            "Epoch 350/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7500\n",
            "Epoch 351/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.7500\n",
            "Epoch 352/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7500\n",
            "Epoch 353/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7500\n",
            "Epoch 354/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7500\n",
            "Epoch 355/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7500\n",
            "Epoch 356/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7500\n",
            "Epoch 357/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7500\n",
            "Epoch 358/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7500\n",
            "Epoch 359/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7500\n",
            "Epoch 360/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7500\n",
            "Epoch 361/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7500\n",
            "Epoch 362/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7500\n",
            "Epoch 363/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7500\n",
            "Epoch 364/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7500\n",
            "Epoch 365/423\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5900 - accuracy: 0.7500\n",
            "Epoch 366/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5896 - accuracy: 0.7500\n",
            "Epoch 367/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7500\n",
            "Epoch 368/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7500\n",
            "Epoch 369/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7500\n",
            "Epoch 370/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7500\n",
            "Epoch 371/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7500\n",
            "Epoch 372/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7500\n",
            "Epoch 373/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7500\n",
            "Epoch 374/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7500\n",
            "Epoch 375/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7500\n",
            "Epoch 376/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7500\n",
            "Epoch 377/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7500\n",
            "Epoch 378/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7500\n",
            "Epoch 379/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.7500\n",
            "Epoch 380/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7500\n",
            "Epoch 381/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7500\n",
            "Epoch 382/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.7500\n",
            "Epoch 383/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.7500\n",
            "Epoch 384/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7500\n",
            "Epoch 385/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7500\n",
            "Epoch 386/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7500\n",
            "Epoch 387/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7500\n",
            "Epoch 388/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7500\n",
            "Epoch 389/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.7500\n",
            "Epoch 390/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.7500\n",
            "Epoch 391/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7500\n",
            "Epoch 392/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7500\n",
            "Epoch 393/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.7500\n",
            "Epoch 394/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7500\n",
            "Epoch 395/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7500\n",
            "Epoch 396/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7500\n",
            "Epoch 397/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7500\n",
            "Epoch 398/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7500\n",
            "Epoch 399/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7500\n",
            "Epoch 400/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7500\n",
            "Epoch 401/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7500\n",
            "Epoch 402/423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7500\n",
            "Epoch 403/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7500\n",
            "Epoch 404/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7500\n",
            "Epoch 405/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7500\n",
            "Epoch 406/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7500\n",
            "Epoch 407/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7500\n",
            "Epoch 408/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7500\n",
            "Epoch 409/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7500\n",
            "Epoch 410/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7500\n",
            "Epoch 411/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7500\n",
            "Epoch 412/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7500\n",
            "Epoch 413/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7500\n",
            "Epoch 414/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7500\n",
            "Epoch 415/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7500\n",
            "Epoch 416/423\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7500\n",
            "Epoch 417/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7500\n",
            "Epoch 418/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7500\n",
            "Epoch 419/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7500\n",
            "Epoch 420/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7500\n",
            "Epoch 421/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7500\n",
            "Epoch 422/423\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7500\n",
            "Epoch 423/423\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f78bd06f7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGiKmD8kJObZ",
        "colab_type": "code",
        "outputId": "45df2f13-d659-41c2-8cab-9b7d86ea650d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, y)\n",
        "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7500\n",
            "accuracy: 75.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8b-r70o8p2Dm"
      },
      "source": [
        "## Try building/training a more complex MLP on a bigger dataset.\n",
        "\n",
        "Use TensorFlow Keras & the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the canonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
        "\n",
        "If you need inspiration, the Internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n",
        "\n",
        "\n",
        "### Parts\n",
        "1. Gathering & Transforming the Data\n",
        "2. Making MNIST a Binary Problem\n",
        "3. Estimating your Neural Network (the part you focus on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLofAvEg67Wp",
        "colab_type": "text"
      },
      "source": [
        "### Gathering the Data \n",
        "\n",
        "`keras` has a handy method to pull the mnist dataset for you. You'll notice that each observation is a 28x28 arrary which represents an image. Although most Neural Network frameworks can handle higher dimensional data, that is more overhead than necessary for us. We need to flatten the image to one long row which will be 784 values (28X28). Basically, you will be appending each row to one another to make on really long row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jidZG_Fc67Wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Stretch - use dropout \n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lFB_P767Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VWJ88xB67W2",
        "colab_type": "code",
        "outputId": "5ef2c973-2a92-4cae-e956-d32dc4356e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm57tFV967W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
        "\n",
        "# Normalize Our Data\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCJxer3u67XE",
        "colab_type": "code",
        "outputId": "f09abcff-45d2-4fa9-c827-c8d501938dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Now the data should be in a format you're more familiar with\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEBYZkFfNOyi",
        "colab_type": "code",
        "outputId": "94ce61f3-3b75-4d0a-8b8e-e4cbb383ac3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VegFFMPW67XI",
        "colab_type": "text"
      },
      "source": [
        "### Making MNIST a Binary Problem \n",
        "MNIST is multiclass classification problem; however we haven't covered all the necessary techniques to handle this yet. You would need to one-hot encode the target, use a different loss metric, and use softmax activations for the last layer. This is all stuff we'll cover later this week, but let us simplify the problem for now: Zero or all else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Q2MuK167XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_temp = np.zeros(y_train.shape)\n",
        "y_temp[np.where(y_train == 0.0)[0]] = 1\n",
        "y_train = y_temp\n",
        "\n",
        "y_temp = np.zeros(y_test.shape)\n",
        "y_temp[np.where(y_test == 0.0)[0]] = 1\n",
        "y_test = y_temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx-54s-p67XM",
        "colab_type": "code",
        "outputId": "598ba37d-6656-433f-9641-93129d12ba99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# A Nice Binary target for ya to work with\n",
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfXddLT367XS",
        "colab_type": "text"
      },
      "source": [
        "### Estimating Your `net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5MOPtYdk1HgA",
        "colab": {}
      },
      "source": [
        "# Stretch - use dropout \n",
        "import numpy as np\n",
        "np.random.seed(810)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usp_GFB_KH8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "for _ in range(6):\n",
        "  model.add(Dense(18, activation='relu'))\n",
        "model.add(Dense(10,activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbYDPJIzKIBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_zqwmJeKIDt",
        "colab_type": "code",
        "outputId": "03010179-9286-476c-dfaf-3f5877633780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2948 - accuracy: 0.5199 - val_loss: 0.8777 - val_accuracy: 0.7011\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7819 - accuracy: 0.7517 - val_loss: 0.6741 - val_accuracy: 0.7925\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6272 - accuracy: 0.8107 - val_loss: 0.5452 - val_accuracy: 0.8363\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5140 - accuracy: 0.8491 - val_loss: 0.4556 - val_accuracy: 0.8686\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4454 - accuracy: 0.8702 - val_loss: 0.4093 - val_accuracy: 0.8804\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3926 - accuracy: 0.8864 - val_loss: 0.3916 - val_accuracy: 0.8857\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3566 - accuracy: 0.8980 - val_loss: 0.3363 - val_accuracy: 0.9029\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3275 - accuracy: 0.9054 - val_loss: 0.3260 - val_accuracy: 0.9065\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3064 - accuracy: 0.9126 - val_loss: 0.3040 - val_accuracy: 0.9152\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2909 - accuracy: 0.9166 - val_loss: 0.3035 - val_accuracy: 0.9140\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2772 - accuracy: 0.9204 - val_loss: 0.2942 - val_accuracy: 0.9160\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2663 - accuracy: 0.9235 - val_loss: 0.3003 - val_accuracy: 0.9116\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2572 - accuracy: 0.9250 - val_loss: 0.2686 - val_accuracy: 0.9248\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2481 - accuracy: 0.9281 - val_loss: 0.2512 - val_accuracy: 0.9289\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2397 - accuracy: 0.9301 - val_loss: 0.2751 - val_accuracy: 0.9201\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2322 - accuracy: 0.9320 - val_loss: 0.2602 - val_accuracy: 0.9249\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2237 - accuracy: 0.9344 - val_loss: 0.2577 - val_accuracy: 0.9238\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2167 - accuracy: 0.9370 - val_loss: 0.2363 - val_accuracy: 0.9310\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2112 - accuracy: 0.9380 - val_loss: 0.2426 - val_accuracy: 0.9284\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2037 - accuracy: 0.9405 - val_loss: 0.2228 - val_accuracy: 0.9362\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2014 - accuracy: 0.9408 - val_loss: 0.2285 - val_accuracy: 0.9326\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1959 - accuracy: 0.9429 - val_loss: 0.2180 - val_accuracy: 0.9382\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9434 - val_loss: 0.2178 - val_accuracy: 0.9352\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1895 - accuracy: 0.9442 - val_loss: 0.2343 - val_accuracy: 0.9318\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1850 - accuracy: 0.9459 - val_loss: 0.2111 - val_accuracy: 0.9413\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1803 - accuracy: 0.9472 - val_loss: 0.2089 - val_accuracy: 0.9403\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1801 - accuracy: 0.9471 - val_loss: 0.2071 - val_accuracy: 0.9399\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1747 - accuracy: 0.9487 - val_loss: 0.2080 - val_accuracy: 0.9395\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1729 - accuracy: 0.9491 - val_loss: 0.2133 - val_accuracy: 0.9388\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1729 - accuracy: 0.9486 - val_loss: 0.1990 - val_accuracy: 0.9424\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1685 - accuracy: 0.9500 - val_loss: 0.2078 - val_accuracy: 0.9385\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1667 - accuracy: 0.9503 - val_loss: 0.2093 - val_accuracy: 0.9390\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1639 - accuracy: 0.9515 - val_loss: 0.2085 - val_accuracy: 0.9394\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1621 - accuracy: 0.9520 - val_loss: 0.2181 - val_accuracy: 0.9377\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1597 - accuracy: 0.9521 - val_loss: 0.2219 - val_accuracy: 0.9362\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1599 - accuracy: 0.9529 - val_loss: 0.2043 - val_accuracy: 0.9393\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1585 - accuracy: 0.9525 - val_loss: 0.2348 - val_accuracy: 0.9353\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1566 - accuracy: 0.9531 - val_loss: 0.2118 - val_accuracy: 0.9408\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1533 - accuracy: 0.9545 - val_loss: 0.1996 - val_accuracy: 0.9429\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1533 - accuracy: 0.9538 - val_loss: 0.1987 - val_accuracy: 0.9432\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1514 - accuracy: 0.9544 - val_loss: 0.2054 - val_accuracy: 0.9429\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1510 - accuracy: 0.9549 - val_loss: 0.2007 - val_accuracy: 0.9416\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1505 - accuracy: 0.9552 - val_loss: 0.1983 - val_accuracy: 0.9435\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1485 - accuracy: 0.9559 - val_loss: 0.2070 - val_accuracy: 0.9421\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1453 - accuracy: 0.9572 - val_loss: 0.2023 - val_accuracy: 0.9445\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1454 - accuracy: 0.9567 - val_loss: 0.1981 - val_accuracy: 0.9466\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1444 - accuracy: 0.9571 - val_loss: 0.1959 - val_accuracy: 0.9428\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1436 - accuracy: 0.9570 - val_loss: 0.2241 - val_accuracy: 0.9371\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1416 - accuracy: 0.9576 - val_loss: 0.2096 - val_accuracy: 0.9393\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1406 - accuracy: 0.9578 - val_loss: 0.2130 - val_accuracy: 0.9406\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1399 - accuracy: 0.9575 - val_loss: 0.2049 - val_accuracy: 0.9418\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1367 - accuracy: 0.9598 - val_loss: 0.2001 - val_accuracy: 0.9449\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1367 - accuracy: 0.9588 - val_loss: 0.1998 - val_accuracy: 0.9442\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1347 - accuracy: 0.9602 - val_loss: 0.2041 - val_accuracy: 0.9429\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1344 - accuracy: 0.9600 - val_loss: 0.2020 - val_accuracy: 0.9449\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1332 - accuracy: 0.9601 - val_loss: 0.2123 - val_accuracy: 0.9420\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1318 - accuracy: 0.9603 - val_loss: 0.2200 - val_accuracy: 0.9404\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1310 - accuracy: 0.9606 - val_loss: 0.2082 - val_accuracy: 0.9433\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1309 - accuracy: 0.9604 - val_loss: 0.2044 - val_accuracy: 0.9454\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1276 - accuracy: 0.9616 - val_loss: 0.2021 - val_accuracy: 0.9430\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1279 - accuracy: 0.9616 - val_loss: 0.1968 - val_accuracy: 0.9454\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1281 - accuracy: 0.9618 - val_loss: 0.1939 - val_accuracy: 0.9455\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1255 - accuracy: 0.9627 - val_loss: 0.2096 - val_accuracy: 0.9444\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1259 - accuracy: 0.9615 - val_loss: 0.2005 - val_accuracy: 0.9451\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1244 - accuracy: 0.9622 - val_loss: 0.2058 - val_accuracy: 0.9443\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1239 - accuracy: 0.9628 - val_loss: 0.2333 - val_accuracy: 0.9365\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1223 - accuracy: 0.9633 - val_loss: 0.2003 - val_accuracy: 0.9448\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1223 - accuracy: 0.9635 - val_loss: 0.1955 - val_accuracy: 0.9444\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1205 - accuracy: 0.9632 - val_loss: 0.2133 - val_accuracy: 0.9423\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1202 - accuracy: 0.9635 - val_loss: 0.2065 - val_accuracy: 0.9443\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1181 - accuracy: 0.9635 - val_loss: 0.2033 - val_accuracy: 0.9444\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1190 - accuracy: 0.9635 - val_loss: 0.1987 - val_accuracy: 0.9461\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1175 - accuracy: 0.9645 - val_loss: 0.2073 - val_accuracy: 0.9438\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1170 - accuracy: 0.9644 - val_loss: 0.2064 - val_accuracy: 0.9457\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1172 - accuracy: 0.9644 - val_loss: 0.2024 - val_accuracy: 0.9455\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1141 - accuracy: 0.9656 - val_loss: 0.2141 - val_accuracy: 0.9432\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1156 - accuracy: 0.9650 - val_loss: 0.2117 - val_accuracy: 0.9448\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1133 - accuracy: 0.9660 - val_loss: 0.2140 - val_accuracy: 0.9452\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1141 - accuracy: 0.9655 - val_loss: 0.2039 - val_accuracy: 0.9446\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1118 - accuracy: 0.9664 - val_loss: 0.2015 - val_accuracy: 0.9469\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1134 - accuracy: 0.9653 - val_loss: 0.2117 - val_accuracy: 0.9462\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1118 - accuracy: 0.9658 - val_loss: 0.2017 - val_accuracy: 0.9462\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1097 - accuracy: 0.9665 - val_loss: 0.1950 - val_accuracy: 0.9468\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1102 - accuracy: 0.9667 - val_loss: 0.2043 - val_accuracy: 0.9460\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1101 - accuracy: 0.9663 - val_loss: 0.2133 - val_accuracy: 0.9461\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1081 - accuracy: 0.9675 - val_loss: 0.2133 - val_accuracy: 0.9443\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1085 - accuracy: 0.9670 - val_loss: 0.2048 - val_accuracy: 0.9466\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1070 - accuracy: 0.9674 - val_loss: 0.2032 - val_accuracy: 0.9466\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9677 - val_loss: 0.2050 - val_accuracy: 0.9447\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1080 - accuracy: 0.9674 - val_loss: 0.2082 - val_accuracy: 0.9448\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1052 - accuracy: 0.9682 - val_loss: 0.2171 - val_accuracy: 0.9432\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1072 - accuracy: 0.9669 - val_loss: 0.2024 - val_accuracy: 0.9476\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1061 - accuracy: 0.9679 - val_loss: 0.2140 - val_accuracy: 0.9468\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1052 - accuracy: 0.9681 - val_loss: 0.2034 - val_accuracy: 0.9466\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1023 - accuracy: 0.9690 - val_loss: 0.2158 - val_accuracy: 0.9441\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1042 - accuracy: 0.9686 - val_loss: 0.2075 - val_accuracy: 0.9455\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1048 - accuracy: 0.9678 - val_loss: 0.2056 - val_accuracy: 0.9468\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1023 - accuracy: 0.9692 - val_loss: 0.2127 - val_accuracy: 0.9457\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1021 - accuracy: 0.9689 - val_loss: 0.2080 - val_accuracy: 0.9464\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1019 - accuracy: 0.9689 - val_loss: 0.2253 - val_accuracy: 0.9443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwlRJSfBlCvy"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Make MNIST a multiclass problem using cross entropy & soft-max\n",
        "- Implement Cross Validation model evaluation on your MNIST implementation \n",
        "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
        " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
        "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
      ]
    }
  ]
}