{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jberkow713 Neural Networks Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jberkow713/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Jberkow713_Neural_Networks_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer:\n",
        "### Hidden Layer:\n",
        "### Output Layer:\n",
        "### Neuron:\n",
        "### Weight:\n",
        "### Activation Function:\n",
        "### Node Map:\n",
        "### Perceptron:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReW06_4iYzbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input Layer: Part of neural network where you input data, weights, alpha(y intercept)\n",
        "\n",
        "# hidden layer: Layer that helps with the calculations, but one in which is sort of built into the neural network itself, and \n",
        "#one in which you don't interact with as much\n",
        "\n",
        "# output layer: layer that gives classifying results \n",
        "\n",
        "# Neuron: individual part of the neural network, sums some value based on weights and other given values, passes it through a sigmoid function\n",
        "# comes up with collective sum as an output which then creates results\n",
        "\n",
        "# weight: weights related to inputs, used in the summation to create output values\n",
        "\n",
        "# activation function : In artificial neural networks, the activation function of a node defines the output \n",
        "#of that node given an input or set of inputs.  The activation function decides whether a cell \"fires\" or not. \n",
        "\n",
        "# node map:  it's a visual diagram of the architecture or \"topology\" of our neural network. \n",
        "#It's kind of like a flow chart in that it shows the path from inputs to outputs. \n",
        "\n",
        "# Perceptron: A perceptron is just a single node or neuron of a neural network with nothing else. \n",
        "# It can take any number of inputs and spit out an output.\n",
        "# y=sigmoid(âˆ‘(weight1input1+weight2input2+weight3input3)+bias) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij-3Gy_XsLLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You take a bunch of Perceptrons, individual nodes, with weights, values, biases...multiply weights by values individual parts, add bias\n",
        "# This is the weighted sum, just dot product of inputs and weights\n",
        "# then you pass this weighted sum through a sigmoid function, it gives you an Activated output. \n",
        "# You then subract the activated output from the correct values, to get an error\n",
        "\n",
        "#You then make an adjustment by multiplying the error by the derivative of the function, using the value of the weighted sum\n",
        "# and through this, you, basically take the slope of the point on the functions curve, to find out which direction the weights\n",
        "#should be increasing or decreasing by, in order to point the neuron closer to the direction you know it should be headed in\\\n",
        "\n",
        "#Now, you update the weights, because the weights are essentially what you are looking for , in order to point specific neurons to specific\n",
        "# targets, and you iterate many many times, until you finally have gotten correct outputs relative to the actual desired output, based \n",
        "# on specific weights\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### Your Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A7B2zFPYfFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "f6cd9995-29be-47f6-9551-5bb1b40f418d"
      },
      "source": [
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  1\n",
              "1   1   0  1\n",
              "2   0   1  1\n",
              "3   1   1  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue5jxSgjyVE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make into array so that it can be used with the activated output, which is also in array form...otherwise error\n",
        "correct_outputs =  ([[1],\n",
        "       [1],\n",
        "       [1],\n",
        "       [0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivate(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOHoXZZsYfFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "dfe96a20-b4f0-4a92-93e1-ddc919f9ccc9"
      },
      "source": [
        "import numpy as np\n",
        "weights = 2 * np.random.random((3,1)) - 1\n",
        "weights"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.64256641],\n",
              "       [ 0.35367557],\n",
              "       [-0.21628238]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4UKRTlD0RGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = np.array([\n",
        "                   [0, 0, 1],\n",
        "                   [1, 0, 1],\n",
        "                   [0, 1, 1],\n",
        "                   [1, 1, 0]\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwNlyNN80RJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNrtvrSV0RLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c95540b7-56e8-417b-e0d7-58565af84c3d"
      },
      "source": [
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4461392 ],\n",
              "       [0.60498598],\n",
              "       [0.53429437],\n",
              "       [0.73031907]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9k-kTw40ROR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "9434ef60-f275-4ed7-fdcd-be08cea22dab"
      },
      "source": [
        "error = correct_outputs - activated_output\n",
        "error "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5538608 ],\n",
              "       [ 0.39501402],\n",
              "       [ 0.46570563],\n",
              "       [-0.73031907]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ls6e7H60RTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5a13236b-f62e-41f2-9609-e27822c0b295"
      },
      "source": [
        "adjustments = error * sigmoid_derivate(weighted_sum)\n",
        "adjustments"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.13685846],\n",
              "       [ 0.09439964],\n",
              "       [ 0.11587869],\n",
              "       [-0.14383862]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvovIlYI0RV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2ba4a127-2e22-474a-dfd6-0eb42ddc132e"
      },
      "source": [
        "weights += np.dot(inputs.T, adjustments)\n",
        "weights"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.59312742],\n",
              "       [0.32571564],\n",
              "       [0.13085441]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa3OujOv0RYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "5285019d-1f0b-4137-9f8b-eb9bf18820a5"
      },
      "source": [
        "for iteration in range(10000):\n",
        "    \n",
        "    # Weighted sum of inputs / weights\n",
        "    weighted_sum = np.dot(inputs, weights)\n",
        "    \n",
        "    # Activate!\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "    \n",
        "    # Cac error\n",
        "    error = correct_outputs - activated_output\n",
        "    \n",
        "    # Can add in learning rate for better performance.\n",
        "    adjustments = error * sigmoid_derivate(weighted_sum)\n",
        "    \n",
        "    # Update the Weights\n",
        "    weights += np.dot(inputs.T, adjustments)\n",
        "    \n",
        "print(\"Weights after training\")\n",
        "print(weights)\n",
        "\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[-2.40970792]\n",
            " [-2.41069947]\n",
            " [ 7.49014758]]\n",
            "Output after training\n",
            "[[0.99944171]\n",
            " [0.99382093]\n",
            " [0.99381484]\n",
            " [0.00799941]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg2TFfW10RbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# so you're left with weights that deliver correct output of 1, 1, 1, 0...through many iterations and updates through the weights\n",
        "#using gradient descent and the sigmoid function...basically"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOXvQiTKYfFm",
        "colab_type": "code",
        "outputId": "32872141-6c71-4e50-b4ee-573e6e134b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "diab= pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diab.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru9L9iDo7JBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "x = diab.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "diab = pd.DataFrame(x_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUYkx6Cp7x3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d26a4d6-ae3f-4116-c2b8-3eabbc879daa"
      },
      "source": [
        "diab.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHEneUxB7JEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "90af4fba-64c2-41a3-96c4-6652a05613a3"
      },
      "source": [
        "diab.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.743719</td>\n",
              "      <td>0.590164</td>\n",
              "      <td>0.353535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500745</td>\n",
              "      <td>0.234415</td>\n",
              "      <td>0.483333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.427136</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.292929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.396423</td>\n",
              "      <td>0.116567</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.919598</td>\n",
              "      <td>0.524590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347243</td>\n",
              "      <td>0.253629</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.447236</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.232323</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.418778</td>\n",
              "      <td>0.038002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.688442</td>\n",
              "      <td>0.327869</td>\n",
              "      <td>0.353535</td>\n",
              "      <td>0.198582</td>\n",
              "      <td>0.642325</td>\n",
              "      <td>0.943638</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...         5         6         7    8\n",
              "0  0.352941  0.743719  0.590164  0.353535  ...  0.500745  0.234415  0.483333  1.0\n",
              "1  0.058824  0.427136  0.540984  0.292929  ...  0.396423  0.116567  0.166667  0.0\n",
              "2  0.470588  0.919598  0.524590  0.000000  ...  0.347243  0.253629  0.183333  1.0\n",
              "3  0.058824  0.447236  0.540984  0.232323  ...  0.418778  0.038002  0.000000  0.0\n",
              "4  0.000000  0.688442  0.327869  0.353535  ...  0.642325  0.943638  0.200000  1.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXgJUByK70u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = diab.iloc[0:768, 8].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ek5WK5E70xJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "01367581-712c-4454-e60a-5942040541a4"
      },
      "source": [
        "x = diab.iloc[0:768, [0, 1, 2, 3, 4, 5, 6, 7]].values\n",
        "x"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMbDAxA870zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_outputs = y\n",
        "inputs = x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGocHqSi9iss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "f2b2852a-2858-4eb4-8967-36dc4794aaae"
      },
      "source": [
        "weights = 2 * np.random.random((9,1)) - 1\n",
        "weights"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.16679604],\n",
              "       [-0.02156276],\n",
              "       [ 0.13290497],\n",
              "       [ 0.75351495],\n",
              "       [ 0.53869099],\n",
              "       [ 0.23197131],\n",
              "       [-0.70952235],\n",
              "       [-0.48825179],\n",
              "       [-0.70694059]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGTyfHbz9iu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmrx_EHg9ixa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activated_output = sigmoid(weighted_sum)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxXCg5I5-IDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "f2e21981-b6e4-496c-c353-d851b80fd42d"
      },
      "source": [
        "error = correct_outputs - activated_output\n",
        "error"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.64689778, -0.35310222,  0.64689778, ..., -0.35310222,\n",
              "         0.64689778, -0.35310222],\n",
              "       [ 0.44494811, -0.55505189,  0.44494811, ..., -0.55505189,\n",
              "         0.44494811, -0.55505189],\n",
              "       [ 0.68297441, -0.31702559,  0.68297441, ..., -0.31702559,\n",
              "         0.68297441, -0.31702559],\n",
              "       ...,\n",
              "       [ 0.41884854, -0.58115146,  0.41884854, ..., -0.58115146,\n",
              "         0.41884854, -0.58115146],\n",
              "       [ 0.6974189 , -0.3025811 ,  0.6974189 , ..., -0.3025811 ,\n",
              "         0.6974189 , -0.3025811 ],\n",
              "       [ 0.41849351, -0.58150649,  0.41849351, ..., -0.58150649,\n",
              "         0.41849351, -0.58150649]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0BirURJ-IF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adjustments = error * sigmoid_derivate(weighted_sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KskFBXTJ-S1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "56091eab-0682-4edb-e357-73e239509237"
      },
      "source": [
        "adjustments"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.14776507, -0.08065598,  0.14776507, ..., -0.08065598,\n",
              "         0.14776507, -0.08065598],\n",
              "       [ 0.10988852, -0.13708077,  0.10988852, ..., -0.13708077,\n",
              "         0.10988852, -0.13708077],\n",
              "       [ 0.14787787, -0.0686425 ,  0.14787787, ..., -0.0686425 ,\n",
              "         0.14787787, -0.0686425 ],\n",
              "       ...,\n",
              "       [ 0.10195378, -0.14146066,  0.10195378, ..., -0.14146066,\n",
              "         0.10195378, -0.14146066],\n",
              "       [ 0.14717337, -0.06385241,  0.14717337, ..., -0.06385241,\n",
              "         0.14717337, -0.06385241],\n",
              "       [ 0.1018432 , -0.1415135 ,  0.1018432 , ..., -0.1415135 ,\n",
              "         0.1018432 , -0.1415135 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_C6lKc3-IIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "582a4aca-8c47-448b-e026-4837c6bb2edb"
      },
      "source": [
        "weights += np.dot(inputs.T, adjustments)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-b773318cd8f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjustments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (9,1) doesn't match the broadcast shape (9,768)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWDd_BfQ-WMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I42doLqJ-WPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mwwWp6V-WRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhnZT8u_YfFs",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN9qA8ymYfFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron:\n",
        "    \n",
        "    def __init__(self, rate = 0.01, niter = 100):\n",
        "        self.rate = rate\n",
        "        self.niter = niter\n",
        "    \n",
        "    def __sigmoid(self, x):\n",
        "        return None\n",
        "    \n",
        "    def __sigmoid_derivative(self, x):\n",
        "        return None\n",
        "\n",
        "    def fit(self, x, y):\n",
        "          x = diab.iloc[0:768, [0, 1, 2, 3, 4, 5, 6, 7]].values\n",
        "          y = diab.iloc[0:768, 8].values\n",
        "    \n",
        "        # Randomly Initialize Weights\n",
        "          self.weight = 2 * np.random.random((9,1)) - 1\n",
        "          self.errors = [] \n",
        "          \n",
        "          for i in range(self.niter):\n",
        "        \n",
        "            correct_outputs = y            \n",
        "            weighted_sum = np.dot(x, weights)\n",
        "            activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "            error += correct_outputs - activated_output\n",
        "            \n",
        "            adjustments = error * sigmoid_derivate(weighted_sum)\n",
        "            \n",
        "            weights += np.dot(inputs.T, adjustments)\n",
        "    \n",
        "            print(\"Weights after training\")\n",
        "            print(weights)\n",
        "\n",
        "            print(\"Output after training\")\n",
        "            print(activated_output)\n",
        "            \n",
        "    def predict(self, x):\n",
        "   \n",
        "        return weights\n",
        "        return activated_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}